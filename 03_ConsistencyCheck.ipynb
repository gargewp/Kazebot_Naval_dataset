{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Папка где исксть таблицы с комментами\n",
    "storage_dir_name = \"RawComments\"\n",
    "\n",
    "# Файл откуда подгружать список видео\n",
    "file_to_analyze_name = \"videos_to_analyze.csv\"\n",
    "\n",
    "# Файл куда сохранять отфильтрованное\n",
    "file_to_analyze_filtered_name = \"videos_to_analyze_filtered.csv\"\n",
    "\n",
    "# Столбцы таблиц с видео\n",
    "column_names_video = [\"id\", \n",
    "                      \"title\",  \n",
    "                      \"publishedAt\", \n",
    "                      \"channelTitle\", \n",
    "                      \"viewCount\", \n",
    "                      \"likeCount\", \n",
    "                      \"dislikeCount\", \n",
    "                      \"commentCount\"]\n",
    "# Столбцы таблиц с комментами\n",
    "column_names_comment = [\"id\",\n",
    "                        \"videoId\",\n",
    "                        \"authorVideoName\",\n",
    "                        \"totalReplyCount\",\n",
    "                        \"likeCount\",\n",
    "                        \"authorDisplayName\",\n",
    "                        \"textDisplay\",\n",
    "                        \"publishedAt\", \"isReply\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Получаем списки скачанных видео (регуляркой по папке) и списки видео для анализа (из таблицы)\n",
    "df_fvideos = pd.read_csv(file_to_analyze_name)[column_names_video]\n",
    "\n",
    "comment_files = [storage_dir_name + \"\"\"/\"\"\" + file_name for file_name in os.listdir(storage_dir_name) \n",
    "                 if file_name.find(\"_video_comments.csv\") >= 0]\n",
    "\n",
    "existed_v_ids = [re.split(storage_dir_name + r'\\/(.*)_video_comments.csv', comment_file)[1] \n",
    "                         for comment_file in comment_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], shape=(0, 3), dtype='<U11')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Сравним количество скачанных комментариев с цифрой из таблицы общих видеозаписей\n",
    "loaded_comments = [[re.split(storage_dir_name + r'\\/(.*)_video_comments.csv', comment_file)[1], \n",
    "                    pd.read_csv(comment_file)[column_names_comment].shape[0]] for comment_file in comment_files]\n",
    "\n",
    "comments_comparisons = []\n",
    "for loaded_comment in loaded_comments:\n",
    "    if not df_fvideos[df_fvideos[\"id\"] == loaded_comment[0]][\"commentCount\"].empty:\n",
    "        comments_comparisons.append(loaded_comment + [df_fvideos[df_fvideos[\"id\"] == loaded_comment[0]][\"commentCount\"].array[0]])\n",
    "    \n",
    "\n",
    "unconsistent_filter = np.array([min(comments_comparison[1], comments_comparison[2]) / max(comments_comparison[1], comments_comparison[2]) \n",
    "                                for comments_comparison in comments_comparisons]) < 0.9\n",
    "\n",
    "unconsistent_videos = np.array(comments_comparisons)[unconsistent_filter]\n",
    "\n",
    "unconsistent_videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Удалим из датафрейма то, что лишнее\n",
    "for unconsistent_video in unconsistent_videos:\n",
    "    df_fvideos = df_fvideos[df_fvideos[\"id\"] != unconsistent_video[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(205, 8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fvideos.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fvideos.to_csv(file_to_analyze_filtered_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
